
height: 8 agents: 5
1. random: -0.4859
2. pg: -0.4542
3. maddpg: -0.1431
4. rule: -0.0040
5. logic_maddpg:-0.0987

height: 15 agents: 5
1. random: -0.486
2. pg:-0.460
3. maddpg: -0.1457
4. rule: -0.00958
5. logic_maddpg:-0.0863


height: 10 agents: 3
1. random: -0.484
2. pg: -0.1752
3. maddpg: -0.1737
4. rule: -0.002014
5. logic_maddpg:-0.0857

height: 10 agents: 5
1. random: -0.4878
2. pg: -0.3678
3. maddpgï¼š-0.1435
4. rule: -0.0283
5. logic_maddpg: -0.0835

height: 10 agents: 7
1. random: -0.4925
2. pg: -0.4915
3. maddpg: -0.1827
4. rule: -0.1558
5. logic_maddpg:-0.115

height: 8 agents: 2
1. random: -0.4881
2. pg: -0.0114
3. maddpg: -0.2216
4. rule: -0.0014

height: 8 agents: 8
1. random: -0.4882
2. pg:-0.4914
3. maddpg: -0.168
4. rule: -0.1683

hyper-para:

maddpg:
    n_episode = 100
    max_steps = 160
    episodes_before_train = 15
    Actor & Critic lr: 0.001
pg:
    MAX_EPISODES = 3000
    MAX_EP_STEPS = 160
    learning_rate=0.004,
    reward_decay=0.9995,